# ğŸ¤– Machine Learning - Projets et Exercices

Ce dossier contient les travaux pratiques et projets de Machine Learning classique couvrant diffÃ©rents aspects de l'apprentissage supervisÃ©.

---

## ğŸ“‚ Contenu

### ğŸ“˜ Livrable_1.ipynb - RÃ©gression LinÃ©aire par Descente de Gradient
**Objectif** : ImplÃ©mentation from scratch d'un algorithme de rÃ©gression linÃ©aire utilisant la descente de gradient.

**Concepts couverts** :
- âœ… GÃ©nÃ©ration de donnÃ©es synthÃ©tiques (relation linÃ©aire avec bruit)
- âœ… ImplÃ©mentation manuelle de la descente de gradient
- âœ… Calcul des gradients pour MSE (Mean Squared Error)
- âœ… Optimisation des paramÃ¨tres (intercept et slope)
- âœ… Visualisation de la convergence
- âœ… Comparaison avec TensorFlow/Keras

**CompÃ©tences** :
- ComprÃ©hension mathÃ©matique de la rÃ©gression linÃ©aire
- Optimisation itÃ©rative
- HyperparamÃ¨tres : learning rate, epochs
- Visualisation avec matplotlib

---

### ğŸ“— Livrable_2.ipynb - Classification et FrontiÃ¨res de DÃ©cision
**Objectif** : Ã‰tude de la rÃ©gression logistique et des frontiÃ¨res de dÃ©cision sur des donnÃ©es de classification.

**Concepts couverts** :
- âœ… GÃ©nÃ©ration de clusters avec numpy
- âœ… Classification binaire avec rÃ©gression logistique
- âœ… Visualisation des frontiÃ¨res de dÃ©cision linÃ©aires
- âœ… Transformation polynomiale des features (kernel trick)
- âœ… FrontiÃ¨res de dÃ©cision non-linÃ©aires
- âœ… Pipeline scikit-learn (preprocessing + model)
- âœ… Comparaison sur dataset `make_moons`

**CompÃ©tences** :
- RÃ©gression logistique
- Feature engineering (transformations polynomiales)
- Pipelines scikit-learn
- Visualisation 2D des dÃ©cisions de classification

---

### ğŸ“™ Livrable_3.ipynb - Deep Learning avec CNNs
**Objectif** : Initiation au Deep Learning avec les rÃ©seaux de neurones convolutionnels (CNN).

**Contenu** :

#### Partie 1 : Convolutions manuelles
- CrÃ©ation d'images RGB 5Ã—5 (3 canaux)
- Construction de couches Conv2D avec TensorFlow/Keras
- Analyse des dimensions : (5,5,3) â†’ (3,3,2)
- Visualisation des feature maps
- ComprÃ©hension du nombre de paramÃ¨tres

#### Partie 2 : CNN complet pour classification
- Architecture multi-couches :
  - Couches de convolution (Conv2D)
  - Couches de pooling (MaxPooling2D)
  - Couches denses (Dense)
  - Dropout pour rÃ©gularisation
- EntraÃ®nement sur donnÃ©es synthÃ©tiques
- Courbes d'apprentissage (loss, accuracy)
- PrÃ©dictions et Ã©valuation

**CompÃ©tences** :
- RÃ©seaux de neurones convolutionnels
- Architecture CNN (Conv â†’ Pool â†’ Dense)
- TensorFlow/Keras API
- Feature extraction avec convolutions
- Visualisation des activations

---

## ğŸ› ï¸ Technologies utilisÃ©es

- **Python 3.x**
- **NumPy** : manipulation de tableaux et calculs numÃ©riques
- **Pandas** : manipulation de donnÃ©es
- **Matplotlib** : visualisations
- **Scikit-learn** : modÃ¨les ML classiques, preprocessing
- **TensorFlow/Keras** : Deep Learning

---

## ğŸ“Š CompÃ©tences dÃ©veloppÃ©es

âœ”ï¸ RÃ©gression linÃ©aire et optimisation par gradient  
âœ”ï¸ Classification binaire et multi-classes  
âœ”ï¸ Feature engineering et transformations  
âœ”ï¸ Deep Learning : rÃ©seaux de neurones convolutionnels  
âœ”ï¸ Visualisation des rÃ©sultats et frontiÃ¨res de dÃ©cision  
âœ”ï¸ Pipelines de preprocessing  
âœ”ï¸ Analyse des hyperparamÃ¨tres  

---

## ğŸš€ Comment utiliser

1. Ouvrir les notebooks avec Jupyter ou VS Code
2. ExÃ©cuter les cellules sÃ©quentiellement
3. Observer les visualisations et les rÃ©sultats
4. ExpÃ©rimenter avec les hyperparamÃ¨tres

---

## ğŸ“ Notes

Ces travaux couvrent les fondamentaux du Machine Learning et du Deep Learning, de l'implÃ©mentation manuelle aux frameworks modernes.
