# üéÆ Reinforcement Learning - Grid World avec Value Iteration

Ce projet pr√©sente une impl√©mentation progressive de l'apprentissage par renforcement (Reinforcement Learning) dans un environnement Grid World, avec 4 programmes de difficult√© croissante d√©montrant diff√©rentes approches d'apprentissage et d'adaptation.

## üìã Programmes

### Programme 1: Agent Random (`prog1_random.py`)
Agent qui explore al√©atoirement jusqu'√† trouver le goal.
- Exploration pure sans apprentissage
- Visualisation en temps r√©el

**Ex√©cution:**
```bash
python prog1_random.py
```

### Programme 2: Value Iteration (`prog2_value_iteration.py`)
Agent intelligent utilisant Value Iteration pour apprendre la politique optimale.
- Algorithme de Value Iteration
- Affichage des Value States (couleurs)
- Affichage de la Politique Optimale (fl√®ches)
- Chemin optimal garanti

**Ex√©cution:**
```bash
python prog2_value_iteration.py
```

### Programme 3: Goal Mobile entre √âpisodes (`prog3_goal_between_episodes.py`)
Value Iteration avec goal qui change de position entre chaque √©pisode.
- R√©-entra√Ænement √† chaque √©pisode
- Adaptation √† diff√©rentes positions de goal
- Visualisation de l'apprentissage continu

**Ex√©cution:**
```bash
python prog3_goal_between_episodes.py
```

### Programme 4: Goal Mobile en Temps R√©el (`prog4_goal_during_episode.py`)
Value Iteration avec goal qui se d√©place PENDANT l'√©pisode.
- Re-planning dynamique
- Goal mobile pendant que l'agent se d√©place
- D√©fi d'apprentissage le plus complexe

**Ex√©cution:**
```bash
python prog4_goal_during_episode.py
```

## üöÄ Installation

```bash
pip install numpy matplotlib gymnasium
```

## üìä Configurations Disponibles

- **SMALL**: 5x5, 1 goal, 1 obstacle (recommand√© pour d√©mo)
- **DEFAULT**: 10x10, 1 goal, 2 obstacles
- **LARGE**: 15x15, 2 goals, 6 obstacles
- **COMPLEX**: 12x12, 3 goals, 10 obstacles

## üéØ Concepts Cl√©s

### Value Iteration
Algorithme de programmation dynamique qui calcule la valeur optimale de chaque √©tat:
```
V(s) = max_a [R(s,a) + Œ≥ √ó V(s')]
```

### Politique Optimale
Meilleure action √† prendre dans chaque √©tat pour maximiser la r√©compense cumulative.

### Visualisation
- üé® **Couleurs**: Value States (rouge‚Üívert = faible‚Üí√©lev√©)
- ‚û°Ô∏è **Fl√®ches**: Direction optimale
- üîµ **Agent**: Position actuelle
- üü° **Goal**: Objectif
- ‚¨õ **Obstacles**: Cases bloqu√©es

## üìà R√©sultats Typiques

### Programme 1 (Random)
- Taux de succ√®s: 20-40%
- Steps: 40-100 (al√©atoire)

### Programme 2 (Value Iteration)
- Taux de succ√®s: 100%
- Steps: Optimal (chemin le plus court)

### Programme 3 (Goal mobile - √©pisodes)
- Taux de succ√®s: 100% par √©pisode
- R√©-apprentissage rapide

### Programme 4 (Goal mobile - temps r√©el)
- Comportement adaptatif
- Re-planning continu

## üéì √Ä propos

Projet d√©velopp√© dans le cadre de la formation GIIADS (G√©nie Informatique - Intelligence Artificielle et Data Science) pour explorer les concepts fondamentaux du Reinforcement Learning.

**Auteur** : Hanane AMCASSOU  
**Formation** : GIIADS 2024-2025

---

## üõ†Ô∏è Technologies utilis√©es

- **Python 3.x**
- **NumPy** : calculs num√©riques et matrices
- **Matplotlib** : visualisation de l'environnement et des trajectoires
- **Gymnasium** : framework pour environnements de RL (successeur de OpenAI Gym)

---

## üìö Concepts th√©oriques

### Apprentissage par Renforcement
L'agent apprend √† prendre des d√©cisions optimales en interagissant avec l'environnement et en recevant des r√©compenses.

### √âquation de Bellman
```
V(s) = max_a [R(s,a) + Œ≥ √ó V(s')]
```
- `V(s)` : Valeur de l'√©tat s
- `R(s,a)` : R√©compense imm√©diate
- `Œ≥` : Facteur d'actualisation
- `V(s')` : Valeur de l'√©tat suivant

### Processus de D√©cision Markovien (MDP)
- **√âtats** : Positions dans la grille
- **Actions** : {Haut, Bas, Gauche, Droite}
- **R√©compenses** : Goal (+1), Obstacle (-1), Step (-0.01)
- **Transitions** : D√©terministes (100% de succ√®s)

---

## üîó Ressources

- [Sutton & Barto - Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book-2nd.html)
- [Gymnasium Documentation](https://gymnasium.farama.org/)
- [OpenAI Spinning Up in Deep RL](https://spinningup.openai.com/)
